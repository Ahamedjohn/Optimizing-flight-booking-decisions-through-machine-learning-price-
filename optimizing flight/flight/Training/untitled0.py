# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FiX_-ic788zVpSPpKPeQ3mFbGlvo4ct2
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data=pd.read_csv("Data_Train.csv")

data.head()

data.shape

#information of dataset

data.info()

data.isnull().sum()

data.dropna(inplace=True)

data.isnull().sum()

#creating list of category columns
category=['Airline','Source','Destination','Additional_Info']
category

for i in category:
  print(i, data[i].unique())

Category_Cols=data.select_dtypes(include=['object']).columns
Category_Cols

#plotting a barchart for each of the categorical value
for column in Category_Cols:
  plt.figure(figsize=(20,4))
  plt.subplot(121)
  data[column].value_counts().plot(kind='bar')
  plt.title(column)

#Since the maximum number of stops is 4, there should be maximum 6 cities in any particular route. we split the data in route columns.
data.Route=data.Route.str.split('->')
data.Route

data['City1']=data.Route.str[0]
data['City2']=data.Route.str[1]
data['City3']=data.Route.str[2]
data['City4']=data.Route.str[3]
data['City5']=data.Route.str[4]
data['City6']=data.Route.str[5]

#we now split the Date column to extract the 'Date','Month' and 'Year'values ,and stored them in new columns in our dataframe
data.Date_of_Journey=data.Date_of_Journey.str.split('/')
data.Date_of_Journey

#Treating the data_column
data['Date']=data.Date_of_Journey.str[0]
data['Month']=data.Date_of_Journey.str[1]
data['Year']=data.Date_of_Journey.str[2]

#In the similiar manner, we split the Dep_Time column, and create separate columns for departure hours and minutes 
data.Dep_Time=data.Dep_Time.str.split(':')

data['Dep_Time_Hour']=data.Dep_Time.str[0]
data['Dep_Time_Mins']=data.Dep_Time.str[1]

data.Arrival_Time=data.Arrival_Time.str.split('')

data['Arrival_date']=data.Arrival_Time.str[1]
data['Time_of_Arrival']=data.Arrival_Time.str[0]

data['Time_of_Arrival']=data.Time_of_Arrival.str.split(' ')

data['Arrival_Time_Hour']=data.Time_of_Arrival.str[0]
data['Arrival_Time_Mins']=data.Time_of_Arrival.str[1]

#Next, we divide the 'Duration' column to 'Travel_hours' and 'Travel_mins
data.Duration=data.Duration.str.split('')

data['Travel_Hours']=data.Duration.str[0]
data['Travel_Hours']=data['Travel_Hours'].str.split('h')
data['Travel_Hours']=data['Travel_Hours'].str[0]
data.Travel_Hours=data.Travel_Hours
data['Travel_Mins']=data.Duration.str[1]

data.Travel_Mins=data.Travel_Mins.str.split('m')
data.Travel_Mins=data.Travel_Mins.str[0]

#we also treat the 'Total_stops' column, and replace non-stop flights with 0 value and extract the integer part of the 'Total_Stops'
data.Total_Stops.replace('non_stop',0,inplace=True)
data.Total_Stops=data.Total_Stops.str.split('')
]data.Total_Stops=data.Total_Stops.str[0]

data.Additional_Info.unique()

data.Additional_Info.replace('No Info','No info',inplace=True)

data.isnull().sum()

#we also drop some columns line 'city6' and 'city5' since majority of the data in these columns was NoN(null)
data.drop(['City4','City5','City6'],axis=1,inplace=True)

data.drop(['Date_of_Journey','Route','Dep_Time','Arrival_Time','Duration'],axis=1, inplace=True)
data.drop(['Time_of_Arrival'],axis=1,inplace=True)

#Checking Null values
data.isnull.sum()

#filling City3 as None ,the missing values are less
data['City3'].fillna('None',inplace=True)

#filling Arrival_Date as departure Date
data['Arrival_date'].fillna(data['Date'],inplace=True)

#filling Travel_Mins as zero(0)
data['Travel_Mins'].fillna(0,inplace=True)

#Changing the numerical columns from object to int
#data.Total_Stops=data.Total_Stops.astype('int64')
data.Date=data.Date.astype('int64')
data.Month=data.Month.astype('int64')
data.Year=data.Year.astype('int64')
data.Dep_Time_Hour=data.Dep_Time_Hour.astype('int64')
data.Dep_Time_Hour=data.Dep_Time_Hour.astype('int64')
data.Dep_Time_Mins=data.Dep_Time_Mins.astype('int64')
data.Arrival_date=data.Arrival_date.astype('int64')
data.Arrival_Time_Hour=data.Arrival_Time_Hour.astype('int64')
data.Arrival_Time_Mins=data.Arrival_Time_Mins.astype('int64')
#data.Travel_Hours=data.Travel_Hours.astype('int64')
data.Travel_Mins=data.Travel_Mins.astype('int64')

data.info()

data.info()

data[data['Travel_Hours']=='5m']

data.drop(index=6474,inplace=True,axis=0)

data.Travel_Hours=data.Travel_Hours.astype('int64')

#Creating list of Different types of columns
categorical=['Airline','Source','Destination','Additional_Info','City1']
numerical=['Total_Stops','Date,''Month','Year','Dep_Time_Hour','Dep_Time_Mins','Arrival_date','Arrival_Time_Hour','Arrival_Time_Mins','Travel_Hours','Travel_Mins']

#plotting Countplots for categorical Data

import seaborn as sns
c=1
plt.figure(figsize=(20,45))

for i in categorical:
  plt.subplot(6,3,c)
  sns.countplot(data[i])
  plt.xticks(rotation=90)
  plt.tight_layout(pad=3.0)
  c=c+1

plt.show()

#Distribution of'PRICE'column
plt.figure(figsize=(15,8))
sns.distplot(data.price)

data.columns

#Checking the relation of price with categorical data
import seaborn as sns
c=1

for i in categorical:
  plt.figure(figsize = (10,20))

  plt.subplot(6,3,c)

  sns.scatterplot(x=data[i],y=data.price)
  plt.xticks(rotation=90)
  #plt.tight_layout(pod=3.0)
  c=c+1
  plt.show

#checking flight with high prices
data[data.price>50000]
data.head()
pd.set_option('display.max_columns',25)

data.head()

data['Year'].max()

sns.heatmap(data.corr(),annot=True)

data.info()

data

#Checking Relation price with numerical values
c=1

for i in numerical:
  plt.figure(figsize=(10,20))
  plt.subplot(6,3,c)
  sns.scatterplot(x=data[i],y=data.price)
  plt.xicks(rotation=90)
  #plt.tight_layout(pod=3.0)
  c=c+1
  plt.show

#Detecting the Outliers
import seaborn as sns
sns.boxplot(data['price'])

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

data.Airline=le.fit_transform(data.Airline)
data.Source=le.fit_transform(data.Source)
data.Destination=le.fit_transform(data.Destination)
data.Total_Stops=le.fit_transform(data.Total_Stops)
data.City1->=le.fit_transform(data.City1->)
data.City2=le.fit_transform(data.City2)
data.City3=le.fit_transform(data.City3)
data.Additional_Info=le.fit_transform(data.Aditional_Info)
data.head()

data.head()

data=data[['Airline','Source','Destination','Date','Month','Year','Dep_Time_Hour','Dep_Time_Mins','Arrival_date','Arrival_Time_Hour','Arrival_Time_Mins','Price']]
data.head()

y=data1['Price']
x=data1.drop(columns=['Price'],axis=1)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random-state=42)

x_train.head()

from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor
rfr=RandomForestRegressor()
gb=GradientBoostingRegressor()
ad=AdaBoostRegressor()

from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
for i in [rfr,gb,ad]:
  i.fit(x_train,y_train)
  y_pred=i.predict(x_test)
  test_score=r2_score(y_test,y_pred)
  train_score=r2_score(y_train,i.predict(x_train))
  if abs(train_score-test_score)<=0.2:
    print(i)
    print("R2 score is",r2_score(y_test,y_pred))
    print("R2 for train data",r2_score(y_train,i.predict(x_train))
    print("Mean Absolute Error is",mean_absolute_error(y_pred,y_test))
    print("Mean squared Error is",mean_squared_error(y_pred,y_test))
    print("Route Mean Squared Error is",mean_absolute_error(y_pred,y_test,squared=False)))

#Libraries to train Neural network
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Activation, Dropout 
from tensorflow.keras.optimizers import Adam

model=keras.Sequential()
model.add(Dense(7,activation='relu',input_dim=11))

model.add(Dense(7,activation='relu'))

model.add(Dense(1,activation='linear'))

model.summary()

model.compile(loss='mse',optimizer='rmsprop',metrics=['mae']

model.fit(x_train,y_train,batch_size=20, epochs=10)

from sklearn.model_selection import cross_val_score
for i in range(2,5):
  cv=cross_val_score(rfr,x,y,cv=i)
  print(rfr,cv.mean())

from sklearn.model_selection import RandomizeSearchCV

paran_grid={'n_estimators':[10,30,50,70,100],'max_depth':[None,1,2,3],'max_features':['auto','sqrt']}

rfr=RandomForestRegressor()
rf_res=RandomizedSearchCV(estimator=rfr,paran_distributions=paran_grid,cv=3,verbose=2,n_jobs=-1)

rf_res.fit(x_train,y_train)

gb_OradientBoostingRegressor()
gb_res=RandomizedSearchCV(estimator=gb,paran_distribution=paran_grid,cv=3,verbose=2,n_jobs=-1)

gb_res.fit(x_train,y_train)

from sklearn.model_selection import cross_val_score
for i in range(2,5):
  cv=cross_val_score(gb,x,y,cv=i)
  print(rfr,cv.mean())

predicted_values=pd.DataFrame({'Actual':y_test,'predicted':y_pred})

predicted_values

import pickle
pickle.dump(rfr,open('model1.pk1','wb'))

#Detecting the Outliers
import seaborn as sns
sns.boxplot(data['price'])

y=data['price']
x=data.drop(columns=['price'],axis=1)

###Scaling the Data
from sklearn.preprocessing import StandardScaler
ss=StandardScaler()

data1=ss.fit_transform(data)
data1=pd.DataFrame(data1,columns=data.columns=data.columns)
data.head()

from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor
rfr=RandomForestRegressor()
gb=GradientBoostingRegressor()
ad=AdaBoostRegressor()

import pickle
pickle.dump(rfr,open('model1.pk1','wb'))

from flask import Flask,render_template, request
import numpy as np
import pickle

model=pickle.load(open(r"model1.pkl",'rb'))

def home():
  return render_template('home.html')

@app.route("/predict")
def home1():
  return render_template('predict.html')

@app.route("/pred",methds=['post','GET'])
def predict(): 
   x=[[int(x) for x in request.form.values()]]
  print(x)

  x=np.array(x)
  print(x.shape)
  
  print(x)
  pred=model.predict(x)
  print(pred)
  return render_template('submit.html',prediction_text=pred)

if __name__=="__main__":
  app.run(debug=False)